{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XjB6OQzuq2bx"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import pickle\n",
        "import heapq\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import LSTM, Dense, Activation\n",
        "from tensorflow.keras.optimizers import RMSprop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GNwO944xp1w-"
      },
      "outputs": [],
      "source": [
        "dataframe = pd.read_csv(\"data.csv\")\n",
        "text = list(dataframe.values)\n",
        "joined_text =' '.join(str(v) for v in text)\n",
        "with open(\"joined_text.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(joined_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ih4nMT50q1u4"
      },
      "outputs": [],
      "source": [
        "partial_text = joined_text[:205000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Don5o7E_3gTH"
      },
      "outputs": [],
      "source": [
        "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
        "tokens = tokenizer.tokenize(partial_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CoEFIUP67FuN"
      },
      "outputs": [],
      "source": [
        "unique_tokens = np.unique(tokens)\n",
        "unique_token_index = {token: index for index, token in enumerate(unique_tokens)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "b3Smh9zu6mxt"
      },
      "outputs": [],
      "source": [
        "n_words = 10\n",
        "input_words = []\n",
        "next_word = []\n",
        "\n",
        "for i in range(len(tokens) - n_words):\n",
        "    input_words.append(tokens[i:i + n_words])\n",
        "\n",
        "    next_word.append(tokens[i + n_words])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "11b4ce79-9fa7-41a2-a71b-c0a2134b16aa"
      },
      "outputs": [],
      "source": [
        "X = np.zeros((len(input_words), n_words, len(unique_tokens)), dtype=bool)  # for each sample, n input words and then a boolean for each possible next word\n",
        "y = np.zeros((len(next_word), len(unique_tokens)), dtype=bool)  # for each sample a boolean for each possible next word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "758caffb-288e-4c16-878d-f969fde3d081"
      },
      "outputs": [],
      "source": [
        "for i, words in enumerate(input_words):\n",
        "    for j, word in enumerate(words):\n",
        "        X[i, j, unique_token_index[word]] = 1\n",
        "    y[i, unique_token_index[next_word[i]]] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "89102ca3-b2fe-4a34-97c2-666164405ae8"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(n_words, len(unique_tokens)), return_sequences=True))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(len(unique_tokens)))\n",
        "model.add(Activation(\"softmax\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "88ad45b0-b793-429a-80f7-105b04e086c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36db2d2f-a50a-4f19-85d4-5c6a72bb3148"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "288/288 [==============================] - 15s 24ms/step - loss: 8.0534 - accuracy: 0.0275\n",
            "Epoch 2/30\n",
            "288/288 [==============================] - 7s 23ms/step - loss: 7.9107 - accuracy: 0.0282\n",
            "Epoch 3/30\n",
            "288/288 [==============================] - 6s 23ms/step - loss: 7.8446 - accuracy: 0.0300\n",
            "Epoch 4/30\n",
            "288/288 [==============================] - 7s 24ms/step - loss: 7.7324 - accuracy: 0.0329\n",
            "Epoch 5/30\n",
            "288/288 [==============================] - 7s 23ms/step - loss: 7.5649 - accuracy: 0.0358\n",
            "Epoch 6/30\n",
            "288/288 [==============================] - 7s 24ms/step - loss: 7.3568 - accuracy: 0.0401\n",
            "Epoch 7/30\n",
            "288/288 [==============================] - 7s 24ms/step - loss: 7.1118 - accuracy: 0.0509\n",
            "Epoch 8/30\n",
            "288/288 [==============================] - 7s 24ms/step - loss: 6.8184 - accuracy: 0.0697\n",
            "Epoch 9/30\n",
            "288/288 [==============================] - 6s 22ms/step - loss: 6.4939 - accuracy: 0.0914\n",
            "Epoch 10/30\n",
            "288/288 [==============================] - 7s 24ms/step - loss: 6.1588 - accuracy: 0.1142\n",
            "Epoch 11/30\n",
            "288/288 [==============================] - 7s 23ms/step - loss: 5.8162 - accuracy: 0.1442\n",
            "Epoch 12/30\n",
            "288/288 [==============================] - 7s 24ms/step - loss: 5.4922 - accuracy: 0.1735\n",
            "Epoch 13/30\n",
            "288/288 [==============================] - 7s 23ms/step - loss: 5.1681 - accuracy: 0.2026\n",
            "Epoch 14/30\n",
            "288/288 [==============================] - 7s 23ms/step - loss: 4.8633 - accuracy: 0.2346\n",
            "Epoch 15/30\n",
            "288/288 [==============================] - 7s 24ms/step - loss: 4.5687 - accuracy: 0.2704\n",
            "Epoch 16/30\n",
            "288/288 [==============================] - 7s 23ms/step - loss: 4.2954 - accuracy: 0.2999\n",
            "Epoch 17/30\n",
            "288/288 [==============================] - 7s 24ms/step - loss: 4.0344 - accuracy: 0.3348\n",
            "Epoch 18/30\n",
            "288/288 [==============================] - 7s 23ms/step - loss: 3.7873 - accuracy: 0.3701\n",
            "Epoch 19/30\n",
            "288/288 [==============================] - 7s 24ms/step - loss: 3.5537 - accuracy: 0.4034\n",
            "Epoch 20/30\n",
            "288/288 [==============================] - 7s 23ms/step - loss: 3.3351 - accuracy: 0.4335\n",
            "Epoch 21/30\n",
            "288/288 [==============================] - 7s 24ms/step - loss: 3.1119 - accuracy: 0.4755\n",
            "Epoch 22/30\n",
            "288/288 [==============================] - 7s 23ms/step - loss: 2.9089 - accuracy: 0.5090\n",
            "Epoch 23/30\n",
            "288/288 [==============================] - 7s 24ms/step - loss: 2.7087 - accuracy: 0.5478\n",
            "Epoch 24/30\n",
            "288/288 [==============================] - 7s 23ms/step - loss: 2.5234 - accuracy: 0.5901\n",
            "Epoch 25/30\n",
            "288/288 [==============================] - 7s 24ms/step - loss: 2.3496 - accuracy: 0.6257\n",
            "Epoch 26/30\n",
            "288/288 [==============================] - 7s 24ms/step - loss: 2.1888 - accuracy: 0.6649\n",
            "Epoch 27/30\n",
            "288/288 [==============================] - 7s 23ms/step - loss: 2.0228 - accuracy: 0.7043\n",
            "Epoch 28/30\n",
            "288/288 [==============================] - 7s 24ms/step - loss: 1.8677 - accuracy: 0.7402\n",
            "Epoch 29/30\n",
            "288/288 [==============================] - 7s 23ms/step - loss: 1.7239 - accuracy: 0.7719\n",
            "Epoch 30/30\n",
            "288/288 [==============================] - 7s 24ms/step - loss: 1.5843 - accuracy: 0.8042\n"
          ]
        }
      ],
      "source": [
        "optimizer = RMSprop(learning_rate=0.01)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "history = model.fit(X, y, batch_size=128, epochs=30, shuffle=True).history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "wz2XzsFu4MmS"
      },
      "outputs": [],
      "source": [
        "model.save(\"text_gen_model2.h5\")\n",
        "with open(\"history2.p\", \"wb\") as f:\n",
        "    pickle.dump(history, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "LS5hxT704PA5"
      },
      "outputs": [],
      "source": [
        "model = load_model(\"text_gen_model2.h5\")\n",
        "history = pickle.load(open(\"history2.p\", \"rb\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Ld74C5XI4Raj"
      },
      "outputs": [],
      "source": [
        "def predict_next_word(input_text, n_best):\n",
        "\n",
        "    X = np.zeros((1, n_words, len(unique_tokens)))\n",
        "    for i, word in enumerate(input_text.split()):\n",
        "        X[0, i, unique_token_index[word]] = 1\n",
        "\n",
        "    predictions = model.predict(X)[0]\n",
        "    return np.argpartition(predictions, -n_best)[-n_best:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hB_6s3kR4T2g",
        "outputId": "88c808d9-fe02-4794-9026-e3ff5594e497"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 635ms/step\n",
            "میکنه\n",
            "خب\n",
            "دیدم\n",
            "اسم\n",
            "چرا\n",
            "وسط\n",
            "توی\n",
            "می\n",
            "باز\n",
            "تو\n",
            "باید\n",
            "کنار\n",
            "میکنن\n",
            "که\n",
            "رو\n",
            "ما\n",
            "اینا\n",
            "فکر\n",
            "خوبه\n",
            "ها\n",
            "خودش\n",
            "میگه\n",
            "ای\n",
            "واقعا\n",
            "کسی\n",
            "تا\n",
            "دارم\n",
            "خیلی\n",
            "آدم\n",
            "هم\n"
          ]
        }
      ],
      "source": [
        "possible = predict_next_word(\"نظام جمهوری اسلامی\", 30)\n",
        "for idx in possible:\n",
        "    print(unique_tokens[idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ll-XSHuU4gbP"
      },
      "outputs": [],
      "source": [
        "def generate_text(input_text, n_words, creativity):\n",
        "    word_sequence = input_text.split()\n",
        "    current = 0\n",
        "    for _ in range(n_words):\n",
        "        sub_sequence = \" \".join(tokenizer.tokenize(\" \".join(word_sequence))[current:current+n_words])\n",
        "        try:\n",
        "            choice = unique_tokens[random.choice(predict_next_word(sub_sequence, creativity))]\n",
        "        except:\n",
        "            choice = random.choice(unique_tokens)\n",
        "        word_sequence.append(choice)\n",
        "        current += 1\n",
        "    return \" \".join(word_sequence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "1edbcd2a-c402-4074-f14c-288faf007220",
        "id": "sXzE6vnbmPQI"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 20ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'نظام جمهوری اسلامی باید'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "generate_text(\"نظام جمهوری اسلامی\", 1, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 601
        },
        "id": "IYD1p-YJ4lK7",
        "outputId": "a2395a7e-18e2-4b52-be95-39b36f10fa90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'من میخوام برم مشهد امشب الان شد بر دارن کجا اسب اشتباه آمریکا تشکیل_شورای_انقلاب اشتباه تو دارن ندارد میکنه شبیه اونم جهان هنوز وقتی بگیرن خمینی ملت درد الان زیر دوست دارن پیش واقعا'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "generate_text(\"من میخوام برم مشهد\", 30, 100)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}